{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6941a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import GNNExplainer\n",
    "\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb3d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import import_ipynb\n",
    "\n",
    "from netwrks_2 import MultiBandAttentionFusion, BandSpecificGraphSAGE\n",
    "\n",
    "\n",
    "\n",
    "def train_with_cross_validation(dataset, model_class, num_epochs=1, n_folds=2, band_names=None):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    if band_names is None:\n",
    "        band_names = [f\"Band {i+1}\" for i in range(len(dataset[0]))]\n",
    "    \n",
    "    min_delta = 0.001\n",
    "    labels = [subject[0][0].y.item() for subject in dataset]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    all_fold_metrics = []\n",
    "    all_band_importances = []\n",
    "    fold_models = []\n",
    "    \n",
    "    fold_idx = 1\n",
    "    best_overall_f1 = 0\n",
    "    best_overall_metrics = None\n",
    "    best_overall_model_state = None\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(range(len(labels)), labels):\n",
    "        print(f\"\\n===== Fold {fold_idx}/{n_folds} =====\")\n",
    "        \n",
    "        train_data = [dataset[i] for i in train_idx]\n",
    "        val_data = [dataset[i] for i in val_idx]\n",
    "        \n",
    "        def count_classes(data):\n",
    "            class0 = sum(1 for subject in data if subject[0][0].y.item() == 0)\n",
    "            return class0, len(data) - class0\n",
    "        \n",
    "        class0_count, class1_count = count_classes(train_data)\n",
    "        print(f\"Training set: Class 0: {class0_count}, Class 1: {class1_count}\")\n",
    "        \n",
    "        class0_count, class1_count = count_classes(val_data)\n",
    "        print(f\"Validation set: Class 0: {class0_count}, Class 1: {class1_count}\")\n",
    "        \n",
    "        num_bands = len(dataset[0])\n",
    "        num_nodes = dataset[0][0][0].x.size(0)\n",
    "        in_channels = dataset[0][0][0].x.size(1)\n",
    "        \n",
    "        best_init_loss = float('inf')\n",
    "        best_init_model = None\n",
    "        \n",
    "        for init_attempt in range(3):\n",
    "            temp_model = model_class(\n",
    "                num_bands=num_bands, \n",
    "                hidden_channels=64, \n",
    "                num_classes=2, \n",
    "                dropout_rate=0.5,\n",
    "                num_nodes=num_nodes,\n",
    "                in_channels=in_channels\n",
    "            ).to(device)\n",
    "            \n",
    "            for module in temp_model.modules():\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(module.weight)\n",
    "                    if module.bias is not None:\n",
    "                        nn.init.zeros_(module.bias)\n",
    "            \n",
    "            temp_model.eval()\n",
    "            init_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in DataLoader(val_data, batch_size=1, shuffle=False, collate_fn=lambda x: x):\n",
    "                    processed_batch = []\n",
    "                    for subject_data in batch:\n",
    "                        processed_subject = []\n",
    "                        for band_graphs in subject_data:\n",
    "                            band_graphs = [g.to(device) for g in band_graphs]\n",
    "                            processed_subject.append(band_graphs)\n",
    "                        processed_batch.append(tuple(processed_subject))\n",
    "                    \n",
    "                    try:\n",
    "                        labels = torch.tensor([subject[0][0].y.item() for subject in batch]).to(device).long()\n",
    "                        outputs = temp_model(processed_batch)\n",
    "                        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                        init_loss += loss.item()\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during initialization validation: {e}\")\n",
    "                        init_loss = float('inf')\n",
    "                        break\n",
    "            \n",
    "            if init_loss < best_init_loss:\n",
    "                best_init_loss = init_loss\n",
    "                best_init_state = temp_model.state_dict().copy()\n",
    "        \n",
    "        model = model_class(\n",
    "            num_bands=num_bands, \n",
    "            hidden_channels=64, \n",
    "            num_classes=2, \n",
    "            dropout_rate=0.5,\n",
    "            num_nodes=num_nodes,\n",
    "            in_channels=in_channels\n",
    "        ).to(device)\n",
    "        model.load_state_dict(best_init_state)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "        \n",
    "        class0_count, class1_count = count_classes(train_data)\n",
    "        total = class0_count + class1_count\n",
    "        \n",
    "        weight_0 = total / (2 * class0_count)\n",
    "        weight_1 = total / (2 * class1_count)\n",
    "        \n",
    "        minority_boost = 1.5\n",
    "        if class1_count < class0_count:\n",
    "            weight_1 *= minority_boost\n",
    "        else:\n",
    "            weight_0 *= minority_boost\n",
    "            \n",
    "        class_weights = torch.tensor([weight_0, weight_1], device=device)\n",
    "        print(f\"Using class weights: {class_weights.cpu().numpy()}\")\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=20,\n",
    "            threshold=0.002,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=1, shuffle=True, collate_fn=lambda x: x)\n",
    "        val_loader = DataLoader(val_data, batch_size=1, shuffle=False, collate_fn=lambda x: x)\n",
    "        \n",
    "        best_val_f1 = 0\n",
    "        best_metrics = None\n",
    "        best_epoch = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        epoch_metrics = []\n",
    "        \n",
    "        with tqdm(total=num_epochs, desc=f\"Training Fold {fold_idx}\", leave=True) as pbar:\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                train_preds, train_true = [], []\n",
    "                \n",
    "                for batch in train_loader:\n",
    "                    processed_batch = []\n",
    "                    for subject_data in batch:\n",
    "                        processed_subject = []\n",
    "                        for band_graphs in subject_data:\n",
    "                            band_graphs = [g.to(device) for g in band_graphs]\n",
    "                            for g in band_graphs:\n",
    "                                if g.y.item() not in [0, 1]:\n",
    "                                    g.y = torch.tensor(1 if g.y.item() == 1 else 0, dtype=g.y.dtype, device=g.y.device)\n",
    "                            processed_subject.append(band_graphs)\n",
    "                        processed_batch.append(tuple(processed_subject))\n",
    "                    \n",
    "                    try:\n",
    "                        labels = torch.tensor([subject[0][0].y.item() for subject in batch]).to(device)\n",
    "                        for i, label in enumerate(labels):\n",
    "                            if label.item() not in [0, 1]:\n",
    "                                labels[i] = torch.tensor(1, dtype=labels.dtype, device=labels.device)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(processed_batch)\n",
    "                        \n",
    "                        if labels.dim() > 1 and labels.size(1) > 1:\n",
    "                            labels = labels.argmax(1)\n",
    "                        else:\n",
    "                            labels = labels.view(-1).long()\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        if hasattr(model, 'l1_loss'):\n",
    "                            loss += model.l1_loss\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        train_loss += loss.item()\n",
    "                        preds = outputs.argmax(1)\n",
    "                        train_preds.extend(preds.cpu().numpy())\n",
    "                        train_true.extend(labels.cpu().numpy())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during training: {e}\")\n",
    "                        raise e\n",
    "                \n",
    "                train_f1 = f1_score(train_true, train_preds, average='weighted')\n",
    "                train_accuracy = accuracy_score(train_true, train_preds)\n",
    "                train_loss /= len(train_loader)\n",
    "                \n",
    "                model.eval()\n",
    "                val_preds, val_true = [], []\n",
    "                val_loss = 0\n",
    "                val_outputs_all = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for batch in val_loader:\n",
    "                        processed_batch = []\n",
    "                        for subject_data in batch:\n",
    "                            processed_subject = []\n",
    "                            for band_graphs in subject_data:\n",
    "                                band_graphs = [g.to(device) for g in band_graphs]\n",
    "                                for g in band_graphs:\n",
    "                                    if g.y.item() not in [0, 1]:\n",
    "                                        g.y = torch.tensor(1 if g.y.item() == 2 else 0, dtype=g.y.dtype, device=g.y.device)\n",
    "                                processed_subject.append(band_graphs)\n",
    "                            processed_batch.append(tuple(processed_subject))\n",
    "                        \n",
    "                        try:\n",
    "                            labels = torch.tensor([subject[0][0].y.item() for subject in batch]).to(device)\n",
    "                            for i, label in enumerate(labels):\n",
    "                                if label.item() not in [0, 1]:\n",
    "                                    labels[i] = torch.tensor(1, dtype=labels.dtype, device=labels.device)\n",
    "                            \n",
    "                            if labels.dim() > 1 and labels.size(1) > 1:\n",
    "                                labels = labels.argmax(1)\n",
    "                            else:\n",
    "                                labels = labels.view(-1).long()\n",
    "                            \n",
    "                            outputs = model(processed_batch)\n",
    "                            val_outputs_all.append(outputs.cpu().numpy())\n",
    "                            val_loss += criterion(outputs, labels).item()\n",
    "                            preds = outputs.argmax(1)\n",
    "                            val_preds.extend(preds.cpu().numpy())\n",
    "                            val_true.extend(labels.cpu().numpy())\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error during validation: {e}\")\n",
    "                            raise e\n",
    "                \n",
    "                val_f1 = f1_score(val_true, val_preds, average='weighted')\n",
    "                val_recall = recall_score(val_true, val_preds, average='weighted')\n",
    "                val_precision = precision_score(val_true, val_preds, average='weighted')\n",
    "                val_accuracy = accuracy_score(val_true, val_preds)\n",
    "                val_loss /= len(val_loader)\n",
    "                \n",
    "                scheduler.step(val_f1)\n",
    "                \n",
    "                val_outputs_all = np.concatenate(val_outputs_all, axis=0)\n",
    "                softmax_outputs = torch.nn.functional.softmax(torch.tensor(val_outputs_all), dim=1).numpy()\n",
    "                avg_confidence = np.mean(np.max(softmax_outputs, axis=1))\n",
    "                \n",
    "                if val_f1 > (best_val_f1 + min_delta):\n",
    "                    best_val_f1 = val_f1\n",
    "                    best_metrics = {\n",
    "                        'f1': val_f1,\n",
    "                        'recall': val_recall,\n",
    "                        'precision': val_precision,\n",
    "                        'accuracy': val_accuracy,\n",
    "                        'train_loss': train_loss,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_preds': val_preds,\n",
    "                        'val_true': val_true,\n",
    "                        'confidence': avg_confidence\n",
    "                    }\n",
    "                    best_epoch = epoch + 1\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "                    no_improve_count = 0\n",
    "                else:\n",
    "                    no_improve_count += 1\n",
    "                \n",
    "                epoch_metrics.append({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'train_loss': train_loss,\n",
    "                    'train_f1': train_f1,\n",
    "                    'train_accuracy': train_accuracy,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_f1': val_f1,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'val_recall': val_recall,\n",
    "                    'val_precision': val_precision,\n",
    "                    'confidence': avg_confidence\n",
    "                })\n",
    "                \n",
    "                pbar.set_postfix(\n",
    "                    train_loss=f\"{train_loss:.4f}\",\n",
    "                    val_loss=f\"{val_loss:.4f}\",\n",
    "                    val_f1=f\"{val_f1:.4f}\",\n",
    "                    best_f1=f\"{best_val_f1:.4f}\",\n",
    "                    best_epoch=best_epoch,\n",
    "                    conf=f\"{avg_confidence:.2f}\"\n",
    "                )\n",
    "                pbar.update(1)\n",
    "        \n",
    "        print(f\"\\nFold {fold_idx} - Best Epoch: {best_epoch}\")\n",
    "        print(f\"Best Validation F1: {best_metrics['f1']:.4f}\")\n",
    "        print(f\"Accuracy: {best_metrics['accuracy']:.4f} | Recall: {best_metrics['recall']:.4f} | Precision: {best_metrics['precision']:.4f}\")\n",
    "        print(f\"Average prediction confidence: {best_metrics['confidence']:.4f}\")\n",
    "        \n",
    "        cm = confusion_matrix(best_metrics['val_true'], best_metrics['val_preds'])\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        \n",
    "        model.load_state_dict(best_model_state)\n",
    "        fold_model = model_class(\n",
    "            num_bands=num_bands, \n",
    "            hidden_channels=64, \n",
    "            num_classes=2, \n",
    "            dropout_rate=0.5, \n",
    "            num_nodes=num_nodes,\n",
    "            in_channels=in_channels\n",
    "        ).to(device)\n",
    "        fold_model.load_state_dict(best_model_state)\n",
    "        fold_models.append(fold_model)\n",
    "        \n",
    "        band_importance = model.get_band_importance()\n",
    "        if band_importance is not None:\n",
    "            print(f\"\\nBand Importance Analysis (Fold {fold_idx}):\")\n",
    "            for i, (band_name, weight) in enumerate(zip(band_names, band_importance)):\n",
    "                print(f\"{band_name}: {weight:.4f} ({weight*100:.1f}%)\")\n",
    "            \n",
    "            best_metrics['band_importance'] = {band: float(weight) for band, weight in zip(band_names, band_importance)}\n",
    "            all_band_importances.append(band_importance)\n",
    "        \n",
    "        all_fold_metrics.append(best_metrics)\n",
    "        \n",
    "        if best_val_f1 > best_overall_f1:\n",
    "            best_overall_f1 = best_val_f1\n",
    "            best_overall_metrics = best_metrics\n",
    "            best_overall_model_state = best_model_state\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    avg_f1 = np.mean([m['f1'] for m in all_fold_metrics])\n",
    "    avg_accuracy = np.mean([m['accuracy'] for m in all_fold_metrics])\n",
    "    avg_recall = np.mean([m['recall'] for m in all_fold_metrics])\n",
    "    avg_precision = np.mean([m['precision'] for m in all_fold_metrics])\n",
    "    \n",
    "    print(\"\\n===== Cross-Validation Results =====\")\n",
    "    print(f\"Average F1: {avg_f1:.4f}\")\n",
    "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    \n",
    "    std_f1 = np.std([m['f1'] for m in all_fold_metrics])\n",
    "    print(f\"F1 Standard Deviation: {std_f1:.4f}\")\n",
    "    \n",
    "    if all_band_importances:\n",
    "        avg_band_importance = np.mean(all_band_importances, axis=0)\n",
    "        print(\"\\nAverage Band Importance Across All Folds:\")\n",
    "        for i, (band_name, weight) in enumerate(zip(band_names, avg_band_importance)):\n",
    "            print(f\"{band_name}: {weight:.4f} ({weight*100:.1f}%)\")\n",
    "    \n",
    "    final_model = model_class(\n",
    "        num_bands=num_bands, \n",
    "        hidden_channels=64, \n",
    "        num_classes=2, \n",
    "        dropout_rate=0.5, \n",
    "        num_nodes=num_nodes,\n",
    "        in_channels=in_channels\n",
    "    ).to(device)\n",
    "    \n",
    "    final_model.load_state_dict(best_overall_model_state)\n",
    "    \n",
    "    class EnsembleModel(nn.Module):\n",
    "        def __init__(self, models):\n",
    "            super(EnsembleModel, self).__init__()\n",
    "            self.model_state_dicts = [model.state_dict() for model in models]\n",
    "            self.template_model = model_class(\n",
    "                num_bands=num_bands, \n",
    "                hidden_channels=64, \n",
    "                num_classes=2, \n",
    "                dropout_rate=0.5, \n",
    "                num_nodes=num_nodes,\n",
    "                in_channels=in_channels\n",
    "            ).to(device)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            outputs = []\n",
    "            for state_dict in self.model_state_dicts:\n",
    "                self.template_model.load_state_dict(state_dict)\n",
    "                self.template_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs.append(self.template_model(x))\n",
    "            \n",
    "            return torch.mean(torch.stack(outputs), dim=0)\n",
    "    \n",
    "    ensemble_model = EnsembleModel(fold_models)\n",
    "    \n",
    "    return final_model, fold_models, ensemble_model, all_fold_metrics, {\n",
    "        'avg_f1': avg_f1,\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'avg_recall': avg_recall,\n",
    "        'avg_precision': avg_precision,\n",
    "        'f1_std': std_f1,\n",
    "        'best_fold_metrics': best_overall_metrics,\n",
    "        'avg_band_importance': {band: float(weight) for band, weight in zip(band_names, avg_band_importance)} if all_band_importances else None\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407fc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
