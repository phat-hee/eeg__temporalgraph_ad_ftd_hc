{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a346e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 88/88 [00:08<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Significant Features (p < 0.05):\n",
      "ch1_spectral_entropy: F = 3.68, p = 0.0312\n",
      "ch2_spectral_entropy: F = 3.55, p = 0.0350\n",
      "ch3_spectral_entropy: F = 4.31, p = 0.0179\n",
      "ch4_spectral_entropy: F = 5.37, p = 0.0073\n",
      "ch4_hjorth_complexity: F = 3.76, p = 0.0293\n",
      "ch5_spectral_entropy: F = 3.49, p = 0.0370\n",
      "ch6_spectral_entropy: F = 3.53, p = 0.0357\n",
      "ch7_mean_psd: F = 5.84, p = 0.0049\n",
      "ch7_spectral_entropy: F = 5.03, p = 0.0097\n",
      "ch7_hjorth_activity: F = 5.95, p = 0.0044\n",
      "ch7_std: F = 6.35, p = 0.0032\n",
      "ch7_rms: F = 6.35, p = 0.0032\n",
      "ch8_spectral_entropy: F = 3.71, p = 0.0305\n",
      "ch9_mean_psd: F = 9.28, p = 0.0003\n",
      "ch9_spectral_entropy: F = 7.91, p = 0.0009\n",
      "ch9_hjorth_activity: F = 9.33, p = 0.0003\n",
      "ch9_hjorth_complexity: F = 4.71, p = 0.0127\n",
      "ch9_std: F = 8.91, p = 0.0004\n",
      "ch9_rms: F = 8.91, p = 0.0004\n",
      "ch10_mean_psd: F = 10.88, p = 0.0001\n",
      "ch10_spectral_entropy: F = 10.19, p = 0.0002\n",
      "ch10_hjorth_activity: F = 10.83, p = 0.0001\n",
      "ch10_hjorth_complexity: F = 4.41, p = 0.0164\n",
      "ch10_std: F = 12.82, p = 0.0000\n",
      "ch10_rms: F = 12.82, p = 0.0000\n",
      "ch11_skew: F = 5.90, p = 0.0046\n",
      "ch12_skew: F = 3.43, p = 0.0392\n",
      "ch13_skew: F = 4.26, p = 0.0187\n",
      "ch15_mean_psd: F = 6.82, p = 0.0022\n",
      "ch15_spectral_entropy: F = 11.44, p = 0.0001\n",
      "ch15_hjorth_activity: F = 6.87, p = 0.0021\n",
      "ch15_hjorth_complexity: F = 4.00, p = 0.0236\n",
      "ch15_std: F = 9.59, p = 0.0003\n",
      "ch15_rms: F = 9.59, p = 0.0003\n",
      "ch16_mean_psd: F = 6.82, p = 0.0022\n",
      "ch16_spectral_entropy: F = 9.62, p = 0.0002\n",
      "ch16_hjorth_activity: F = 6.84, p = 0.0022\n",
      "ch16_hjorth_complexity: F = 3.35, p = 0.0419\n",
      "ch16_std: F = 6.79, p = 0.0022\n",
      "ch16_rms: F = 6.79, p = 0.0022\n",
      "ch17_spectral_entropy: F = 4.49, p = 0.0153\n",
      "ch19_mean_psd: F = 4.54, p = 0.0147\n",
      "ch19_spectral_entropy: F = 3.67, p = 0.0317\n",
      "ch19_hjorth_activity: F = 4.70, p = 0.0129\n",
      "ch19_std: F = 4.93, p = 0.0105\n",
      "ch19_rms: F = 4.93, p = 0.0105\n",
      "\n",
      "Random Forest Accuracy: 0.5556\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70         9\n",
      "           1       0.44      0.57      0.50         7\n",
      "           2       0.57      0.36      0.44        11\n",
      "\n",
      "    accuracy                           0.56        27\n",
      "   macro avg       0.55      0.57      0.55        27\n",
      "weighted avg       0.56      0.56      0.54        27\n",
      "\n",
      "\n",
      "Top 10 Important Features:\n",
      "ch13_skew: 0.0769\n",
      "ch11_skew: 0.0748\n",
      "ch10_spectral_entropy: 0.0482\n",
      "ch9_spectral_entropy: 0.0451\n",
      "ch8_spectral_entropy: 0.0423\n",
      "ch10_std: 0.0389\n",
      "ch12_skew: 0.0388\n",
      "ch15_spectral_entropy: 0.0383\n",
      "ch16_spectral_entropy: 0.0372\n",
      "ch5_spectral_entropy: 0.0331\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.signal import welch\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy as shannon_entropy\n",
    "\n",
    "# Constants\n",
    "INPUT_DIR = \"C:\\\\Users\\\\fathi\\\\Desktop\\\\Rest_eeg_ds004504-download\\\\derivatives\\\\500hz_bands\\\\alpha\\\\numpy\"\n",
    "SAMPLE_RATE = 500\n",
    "WINDOW_SIZE = 4 * SAMPLE_RATE  # 4 seconds\n",
    "\n",
    "# Label mapping\n",
    "def get_label(s):\n",
    "    if 1 <= s <= 36:\n",
    "        return 2  # Alzheimer's\n",
    "    elif 37 <= s <= 65:\n",
    "        return 0  # Healthy Control\n",
    "    elif 66 <= s <= 88:\n",
    "        return 1  # Dementia\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Hjorth parameters\n",
    "def hjorth_parameters(signal):\n",
    "    first_deriv = np.diff(signal)\n",
    "    second_deriv = np.diff(first_deriv)\n",
    "    activity = np.var(signal)\n",
    "    mobility = np.sqrt(np.var(first_deriv) / activity) if activity != 0 else 0\n",
    "    complexity = (np.sqrt(np.var(second_deriv) / np.var(first_deriv))\n",
    "                  if np.var(first_deriv) != 0 else 0)\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "# Feature extractor per window/channel\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch in range(window.shape[1]):\n",
    "        x = window[:, ch]\n",
    "\n",
    "        # Welch PSD\n",
    "        f, psd = welch(x, fs=SAMPLE_RATE, nperseg=window.shape[0])\n",
    "        total_power = np.sum(psd)\n",
    "        mean_psd = np.mean(psd)\n",
    "        rel_power = mean_psd / total_power if total_power > 0 else 0\n",
    "        psd_norm = psd / np.sum(psd) if np.sum(psd) > 0 else np.ones_like(psd) / len(psd)\n",
    "        spec_entropy = shannon_entropy(psd_norm)\n",
    "\n",
    "        # Hjorth\n",
    "        act, mob, comp = hjorth_parameters(x)\n",
    "\n",
    "        # Additional features\n",
    "        mean_val = np.mean(x)\n",
    "        std_val = np.std(x)\n",
    "        skew_val = skew(x)\n",
    "        kurt_val = kurtosis(x)\n",
    "        rms = np.sqrt(np.mean(x**2))\n",
    "        zero_crossings = ((x[:-1] * x[1:]) < 0).sum()\n",
    "\n",
    "        features.extend([\n",
    "            mean_psd, rel_power, spec_entropy, act, mob, comp,\n",
    "            mean_val, std_val, skew_val, kurt_val, rms, zero_crossings\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "# Load EEG data\n",
    "subject_data = {}\n",
    "all_files = [\n",
    "    f for f in os.listdir(INPUT_DIR)\n",
    "    if f.endswith(\".npy\") and f.startswith(\"sub-\")\n",
    "]\n",
    "\n",
    "for fn in tqdm(all_files, desc=\"Loading data\"):\n",
    "    stem, _ = os.path.splitext(fn)\n",
    "    subj_prefix = stem.split(\"_\")[0]\n",
    "    try:\n",
    "        subj_id = int(subj_prefix.replace(\"sub-\", \"\"))\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    label = get_label(subj_id)\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "    eeg_path = os.path.join(INPUT_DIR, fn)\n",
    "    time_series = np.load(eeg_path)\n",
    "    if time_series.shape[0] < time_series.shape[1]:\n",
    "        time_series = time_series.T\n",
    "\n",
    "    subject_data[subj_id] = {\n",
    "        \"data\": time_series,\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "# Get number of EEG channels from first subject\n",
    "num_channels = next(iter(subject_data.values()))[\"data\"].shape[1]\n",
    "\n",
    "# Feature name generation\n",
    "channel_feature_names = [\n",
    "    \"mean_psd\", \"rel_power\", \"spectral_entropy\",\n",
    "    \"hjorth_activity\", \"hjorth_mobility\", \"hjorth_complexity\",\n",
    "    \"mean\", \"std\", \"skew\", \"kurtosis\", \"rms\", \"zero_crossings\"\n",
    "]\n",
    "\n",
    "all_feature_names = []\n",
    "for ch in range(num_channels):\n",
    "    for fname in channel_feature_names:\n",
    "        all_feature_names.append(f\"ch{ch+1}_{fname}\")\n",
    "\n",
    "# Train-test split\n",
    "subject_ids = list(subject_data.keys())\n",
    "labels = [subject_data[s][\"label\"] for s in subject_ids]\n",
    "train_ids, test_ids = train_test_split(subject_ids, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Subject-level feature extraction (aggregate mean per subject)\n",
    "def process_subjects(subject_ids):\n",
    "    all_feats, all_labels = [], []\n",
    "    for sid in subject_ids:\n",
    "        ts = subject_data[sid][\"data\"]\n",
    "        label = subject_data[sid][\"label\"]\n",
    "        subj_feats = []\n",
    "        for start in range(0, ts.shape[0] - WINDOW_SIZE + 1, WINDOW_SIZE):\n",
    "            window = ts[start:start + WINDOW_SIZE, :]\n",
    "            feats = extract_features(window)\n",
    "            subj_feats.append(feats)\n",
    "        # Aggregate across all windows for this subject (mean)\n",
    "        subj_feats = np.mean(subj_feats, axis=0)\n",
    "        all_feats.append(subj_feats)\n",
    "        all_labels.append(label)\n",
    "    return np.array(all_feats), np.array(all_labels)\n",
    "\n",
    "train_X, train_y = process_subjects(train_ids)\n",
    "test_X, test_y = process_subjects(test_ids)\n",
    "\n",
    "# ANOVA\n",
    "f_scores = []\n",
    "p_values = []\n",
    "for i in range(train_X.shape[1]):\n",
    "    group_feats = [train_X[train_y == c, i] for c in np.unique(train_y)]\n",
    "    f, p = f_oneway(*group_feats)\n",
    "    f_scores.append(f)\n",
    "    p_values.append(p)\n",
    "\n",
    "# Report significant features\n",
    "print(\"\\nSignificant Features (p < 0.05):\")\n",
    "for i, (f, p) in enumerate(zip(f_scores, p_values)):\n",
    "    if p < 0.05:\n",
    "        print(f\"{all_feature_names[i]}: F = {f:.2f}, p = {p:.4f}\")\n",
    "\n",
    "# Filter features by ANOVA p-values\n",
    "significant_indices = [i for i, p in enumerate(p_values) if p < 0.05]\n",
    "train_X_filtered = train_X[:, significant_indices]\n",
    "test_X_filtered = test_X[:, significant_indices]\n",
    "filtered_feature_names = [all_feature_names[i] for i in significant_indices]\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(train_X_filtered, train_y)\n",
    "\n",
    "# Evaluate\n",
    "pred_y = rf.predict(test_X_filtered)\n",
    "acc = accuracy_score(test_y, pred_y)\n",
    "print(f\"\\nRandom Forest Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_y, pred_y))\n",
    "\n",
    "# Feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_weights = sorted(zip(filtered_feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "for feat, weight in feature_weights[:10]:\n",
    "    print(f\"{feat}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b647440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 88/88 [00:06<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Significant Features (p < 0.05):\n",
      "ch1_rel_power: F = 4.43, p = 0.0162\n",
      "ch1_spectral_entropy: F = 3.69, p = 0.0309\n",
      "ch1_skew: F = 4.09, p = 0.0218\n",
      "ch2_rel_power: F = 4.43, p = 0.0162\n",
      "ch2_spectral_entropy: F = 3.68, p = 0.0312\n",
      "ch3_rel_power: F = 4.43, p = 0.0162\n",
      "ch3_spectral_entropy: F = 4.18, p = 0.0201\n",
      "ch4_rel_power: F = 4.43, p = 0.0162\n",
      "ch4_spectral_entropy: F = 5.43, p = 0.0069\n",
      "ch4_hjorth_complexity: F = 3.61, p = 0.0333\n",
      "ch5_rel_power: F = 4.43, p = 0.0162\n",
      "ch5_spectral_entropy: F = 3.48, p = 0.0374\n",
      "ch6_rel_power: F = 4.43, p = 0.0162\n",
      "ch7_mean_psd: F = 6.02, p = 0.0042\n",
      "ch7_rel_power: F = 4.43, p = 0.0162\n",
      "ch7_spectral_entropy: F = 5.85, p = 0.0048\n",
      "ch7_hjorth_activity: F = 5.95, p = 0.0045\n",
      "ch7_std: F = 6.33, p = 0.0033\n",
      "ch7_rms: F = 6.33, p = 0.0033\n",
      "ch8_rel_power: F = 4.43, p = 0.0162\n",
      "ch8_spectral_entropy: F = 3.69, p = 0.0310\n",
      "ch9_mean_psd: F = 9.42, p = 0.0003\n",
      "ch9_rel_power: F = 4.43, p = 0.0162\n",
      "ch9_spectral_entropy: F = 8.41, p = 0.0006\n",
      "ch9_hjorth_activity: F = 9.33, p = 0.0003\n",
      "ch9_hjorth_complexity: F = 4.61, p = 0.0139\n",
      "ch9_std: F = 8.87, p = 0.0004\n",
      "ch9_rms: F = 8.87, p = 0.0004\n",
      "ch10_mean_psd: F = 10.98, p = 0.0001\n",
      "ch10_rel_power: F = 4.43, p = 0.0162\n",
      "ch10_spectral_entropy: F = 10.07, p = 0.0002\n",
      "ch10_hjorth_activity: F = 10.83, p = 0.0001\n",
      "ch10_hjorth_complexity: F = 4.31, p = 0.0180\n",
      "ch10_std: F = 12.79, p = 0.0000\n",
      "ch10_rms: F = 12.79, p = 0.0000\n",
      "ch11_rel_power: F = 4.43, p = 0.0162\n",
      "ch11_skew: F = 7.72, p = 0.0011\n",
      "ch12_rel_power: F = 4.43, p = 0.0162\n",
      "ch13_rel_power: F = 4.43, p = 0.0162\n",
      "ch13_skew: F = 4.52, p = 0.0149\n",
      "ch14_rel_power: F = 4.43, p = 0.0162\n",
      "ch15_mean_psd: F = 6.97, p = 0.0019\n",
      "ch15_rel_power: F = 4.43, p = 0.0162\n",
      "ch15_spectral_entropy: F = 11.81, p = 0.0000\n",
      "ch15_hjorth_activity: F = 6.88, p = 0.0021\n",
      "ch15_hjorth_complexity: F = 3.90, p = 0.0258\n",
      "ch15_std: F = 9.58, p = 0.0003\n",
      "ch15_rms: F = 9.58, p = 0.0003\n",
      "ch16_mean_psd: F = 7.09, p = 0.0018\n",
      "ch16_rel_power: F = 4.43, p = 0.0162\n",
      "ch16_spectral_entropy: F = 9.01, p = 0.0004\n",
      "ch16_hjorth_activity: F = 6.83, p = 0.0022\n",
      "ch16_hjorth_complexity: F = 3.24, p = 0.0463\n",
      "ch16_std: F = 6.76, p = 0.0023\n",
      "ch16_kurtosis: F = 3.49, p = 0.0369\n",
      "ch16_rms: F = 6.76, p = 0.0023\n",
      "ch17_rel_power: F = 4.43, p = 0.0162\n",
      "ch17_spectral_entropy: F = 4.41, p = 0.0164\n",
      "ch18_rel_power: F = 4.43, p = 0.0162\n",
      "ch19_mean_psd: F = 4.64, p = 0.0135\n",
      "ch19_rel_power: F = 4.43, p = 0.0162\n",
      "ch19_spectral_entropy: F = 3.95, p = 0.0246\n",
      "ch19_hjorth_activity: F = 4.70, p = 0.0129\n",
      "ch19_std: F = 4.93, p = 0.0105\n",
      "ch19_rms: F = 4.93, p = 0.0105\n",
      "\n",
      "--- Random Forest Classifier ---\n",
      "Accuracy: 0.5555555555555556\n",
      "Feature Importances:\n",
      "ch1_rel_power: 0.0000\n",
      "ch1_spectral_entropy: 0.0242\n",
      "ch1_skew: 0.0486\n",
      "ch2_rel_power: 0.0000\n",
      "ch2_spectral_entropy: 0.0240\n",
      "ch3_rel_power: 0.0000\n",
      "ch3_spectral_entropy: 0.0271\n",
      "ch4_rel_power: 0.0000\n",
      "ch4_spectral_entropy: 0.0235\n",
      "ch4_hjorth_complexity: 0.0312\n",
      "ch5_rel_power: 0.0000\n",
      "ch5_spectral_entropy: 0.0238\n",
      "ch6_rel_power: 0.0000\n",
      "ch7_mean_psd: 0.0000\n",
      "ch7_rel_power: 0.0000\n",
      "ch7_spectral_entropy: 0.0297\n",
      "ch7_hjorth_activity: 0.0000\n",
      "ch7_std: 0.0118\n",
      "ch7_rms: 0.0177\n",
      "ch8_rel_power: 0.0000\n",
      "ch8_spectral_entropy: 0.0291\n",
      "ch9_mean_psd: 0.0000\n",
      "ch9_rel_power: 0.0000\n",
      "ch9_spectral_entropy: 0.0496\n",
      "ch9_hjorth_activity: 0.0000\n",
      "ch9_hjorth_complexity: 0.0195\n",
      "ch9_std: 0.0232\n",
      "ch9_rms: 0.0253\n",
      "ch10_mean_psd: 0.0000\n",
      "ch10_rel_power: 0.0000\n",
      "ch10_spectral_entropy: 0.0543\n",
      "ch10_hjorth_activity: 0.0000\n",
      "ch10_hjorth_complexity: 0.0293\n",
      "ch10_std: 0.0185\n",
      "ch10_rms: 0.0352\n",
      "ch11_rel_power: 0.0000\n",
      "ch11_skew: 0.0741\n",
      "ch12_rel_power: 0.0000\n",
      "ch13_rel_power: 0.0000\n",
      "ch13_skew: 0.0506\n",
      "ch14_rel_power: 0.0000\n",
      "ch15_mean_psd: 0.0000\n",
      "ch15_rel_power: 0.0000\n",
      "ch15_spectral_entropy: 0.0314\n",
      "ch15_hjorth_activity: 0.0000\n",
      "ch15_hjorth_complexity: 0.0257\n",
      "ch15_std: 0.0282\n",
      "ch15_rms: 0.0305\n",
      "ch16_mean_psd: 0.0000\n",
      "ch16_rel_power: 0.0000\n",
      "ch16_spectral_entropy: 0.0336\n",
      "ch16_hjorth_activity: 0.0000\n",
      "ch16_hjorth_complexity: 0.0263\n",
      "ch16_std: 0.0149\n",
      "ch16_kurtosis: 0.0362\n",
      "ch16_rms: 0.0161\n",
      "ch17_rel_power: 0.0000\n",
      "ch17_spectral_entropy: 0.0268\n",
      "ch18_rel_power: 0.0000\n",
      "ch19_mean_psd: 0.0000\n",
      "ch19_rel_power: 0.0000\n",
      "ch19_spectral_entropy: 0.0296\n",
      "ch19_hjorth_activity: 0.0000\n",
      "ch19_std: 0.0168\n",
      "ch19_rms: 0.0134\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60         9\n",
      "           1       0.50      0.43      0.46         7\n",
      "           2       0.60      0.55      0.57        11\n",
      "\n",
      "    accuracy                           0.56        27\n",
      "   macro avg       0.55      0.55      0.54        27\n",
      "weighted avg       0.56      0.56      0.55        27\n",
      "\n",
      "\n",
      "--- XGBoost Classifier ---\n",
      "Accuracy: 0.48148148148148145\n",
      "Feature Importances:\n",
      "ch1_rel_power: 0.0000\n",
      "ch1_spectral_entropy: 0.0336\n",
      "ch1_skew: 0.0279\n",
      "ch2_rel_power: 0.0000\n",
      "ch2_spectral_entropy: 0.0126\n",
      "ch3_rel_power: 0.0000\n",
      "ch3_spectral_entropy: 0.0335\n",
      "ch4_rel_power: 0.0000\n",
      "ch4_spectral_entropy: 0.0178\n",
      "ch4_hjorth_complexity: 0.0303\n",
      "ch5_rel_power: 0.0000\n",
      "ch5_spectral_entropy: 0.0026\n",
      "ch6_rel_power: 0.0000\n",
      "ch7_mean_psd: 0.0208\n",
      "ch7_rel_power: 0.0000\n",
      "ch7_spectral_entropy: 0.0406\n",
      "ch7_hjorth_activity: 0.0000\n",
      "ch7_std: 0.0077\n",
      "ch7_rms: 0.0000\n",
      "ch8_rel_power: 0.0000\n",
      "ch8_spectral_entropy: 0.0031\n",
      "ch9_mean_psd: 0.0649\n",
      "ch9_rel_power: 0.0000\n",
      "ch9_spectral_entropy: 0.0091\n",
      "ch9_hjorth_activity: 0.0105\n",
      "ch9_hjorth_complexity: 0.0185\n",
      "ch9_std: 0.0000\n",
      "ch9_rms: 0.0000\n",
      "ch10_mean_psd: 0.0169\n",
      "ch10_rel_power: 0.0000\n",
      "ch10_spectral_entropy: 0.1421\n",
      "ch10_hjorth_activity: 0.0034\n",
      "ch10_hjorth_complexity: 0.0183\n",
      "ch10_std: 0.0212\n",
      "ch10_rms: 0.0000\n",
      "ch11_rel_power: 0.0000\n",
      "ch11_skew: 0.0592\n",
      "ch12_rel_power: 0.0000\n",
      "ch13_rel_power: 0.0000\n",
      "ch13_skew: 0.0382\n",
      "ch14_rel_power: 0.0000\n",
      "ch15_mean_psd: 0.0218\n",
      "ch15_rel_power: 0.0000\n",
      "ch15_spectral_entropy: 0.0127\n",
      "ch15_hjorth_activity: 0.0568\n",
      "ch15_hjorth_complexity: 0.0638\n",
      "ch15_std: 0.0048\n",
      "ch15_rms: 0.0000\n",
      "ch16_mean_psd: 0.0396\n",
      "ch16_rel_power: 0.0000\n",
      "ch16_spectral_entropy: 0.0307\n",
      "ch16_hjorth_activity: 0.0020\n",
      "ch16_hjorth_complexity: 0.0362\n",
      "ch16_std: 0.0021\n",
      "ch16_kurtosis: 0.0332\n",
      "ch16_rms: 0.0000\n",
      "ch17_rel_power: 0.0000\n",
      "ch17_spectral_entropy: 0.0400\n",
      "ch18_rel_power: 0.0000\n",
      "ch19_mean_psd: 0.0000\n",
      "ch19_rel_power: 0.0000\n",
      "ch19_spectral_entropy: 0.0173\n",
      "ch19_hjorth_activity: 0.0000\n",
      "ch19_std: 0.0067\n",
      "ch19_rms: 0.0000\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63         9\n",
      "           1       0.29      0.29      0.29         7\n",
      "           2       0.50      0.45      0.48        11\n",
      "\n",
      "    accuracy                           0.48        27\n",
      "   macro avg       0.46      0.47      0.46        27\n",
      "weighted avg       0.48      0.48      0.48        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:34:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway, skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import welch\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy as shannon_entropy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Constants\n",
    "INPUT_DIR = \"C:\\\\Users\\\\fathi\\\\Desktop\\\\Rest_eeg_ds004504-download\\\\derivatives\\\\500hz_bands\\\\alpha\\\\numpy\"\n",
    "SAMPLE_RATE = 500\n",
    "WINDOW_SIZE = 3 * SAMPLE_RATE  # 4 seconds\n",
    "\n",
    "# Label mapping\n",
    "def get_label(s):\n",
    "    if 1 <= s <= 36:\n",
    "        return 2  # Alzheimer's\n",
    "    elif 37 <= s <= 65:\n",
    "        return 0  # Healthy Control\n",
    "    elif 66 <= s <= 88:\n",
    "        return 1  # Dementia\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Hjorth parameters\n",
    "def hjorth_parameters(signal):\n",
    "    first_deriv = np.diff(signal)\n",
    "    second_deriv = np.diff(first_deriv)\n",
    "    activity = np.var(signal)\n",
    "    mobility = np.sqrt(np.var(first_deriv) / activity) if activity != 0 else 0\n",
    "    complexity = (np.sqrt(np.var(second_deriv) / np.var(first_deriv))\n",
    "                  if np.var(first_deriv) != 0 else 0)\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "# Feature extractor per window/channel\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch in range(window.shape[1]):\n",
    "        x = window[:, ch]\n",
    "\n",
    "        # Welch PSD\n",
    "        f, psd = welch(x, fs=SAMPLE_RATE, nperseg=window.shape[0])\n",
    "        total_power = np.sum(psd)\n",
    "        mean_psd = np.mean(psd)\n",
    "        rel_power = mean_psd / total_power if total_power > 0 else 0\n",
    "        psd_norm = psd / np.sum(psd) if np.sum(psd) > 0 else np.ones_like(psd) / len(psd)\n",
    "        spec_entropy = shannon_entropy(psd_norm)\n",
    "\n",
    "        # Hjorth\n",
    "        act, mob, comp = hjorth_parameters(x)\n",
    "\n",
    "        # Additional features\n",
    "        mean_val = np.mean(x)\n",
    "        std_val = np.std(x)\n",
    "        skew_val = skew(x)\n",
    "        kurt_val = kurtosis(x)\n",
    "        rms = np.sqrt(np.mean(x**2))\n",
    "        zero_crossings = ((x[:-1] * x[1:]) < 0).sum()\n",
    "\n",
    "        features.extend([\n",
    "            mean_psd, rel_power, spec_entropy, act, mob, comp,\n",
    "            mean_val, std_val, skew_val, kurt_val, rms, zero_crossings\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "# Load EEG data\n",
    "subject_data = {}\n",
    "all_files = [\n",
    "    f for f in os.listdir(INPUT_DIR)\n",
    "    if f.endswith(\".npy\") and f.startswith(\"sub-\")\n",
    "]\n",
    "\n",
    "for fn in tqdm(all_files, desc=\"Loading data\"):\n",
    "    stem, _ = os.path.splitext(fn)\n",
    "    subj_prefix = stem.split(\"_\")[0]\n",
    "    try:\n",
    "        subj_id = int(subj_prefix.replace(\"sub-\", \"\"))\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    label = get_label(subj_id)\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "    eeg_path = os.path.join(INPUT_DIR, fn)\n",
    "    time_series = np.load(eeg_path)\n",
    "    if time_series.shape[0] < time_series.shape[1]:\n",
    "        time_series = time_series.T\n",
    "\n",
    "    subject_data[subj_id] = {\n",
    "        \"data\": time_series,\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "# Get number of EEG channels from first subject\n",
    "num_channels = next(iter(subject_data.values()))[\"data\"].shape[1]\n",
    "\n",
    "# Feature name generation\n",
    "channel_feature_names = [\n",
    "    \"mean_psd\", \"rel_power\", \"spectral_entropy\",\n",
    "    \"hjorth_activity\", \"hjorth_mobility\", \"hjorth_complexity\",\n",
    "    \"mean\", \"std\", \"skew\", \"kurtosis\", \"rms\", \"zero_crossings\"\n",
    "]\n",
    "\n",
    "all_feature_names = []\n",
    "for ch in range(num_channels):\n",
    "    for fname in channel_feature_names:\n",
    "        all_feature_names.append(f\"ch{ch+1}_{fname}\")\n",
    "\n",
    "# Train-test split\n",
    "subject_ids = list(subject_data.keys())\n",
    "labels = [subject_data[s][\"label\"] for s in subject_ids]\n",
    "train_ids, test_ids = train_test_split(subject_ids, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Subject-level feature extraction (aggregate mean per subject)\n",
    "def process_subjects(subject_ids):\n",
    "    all_feats, all_labels = [], []\n",
    "    for sid in subject_ids:\n",
    "        ts = subject_data[sid][\"data\"]\n",
    "        label = subject_data[sid][\"label\"]\n",
    "        subj_feats = []\n",
    "        for start in range(0, ts.shape[0] - WINDOW_SIZE + 1, WINDOW_SIZE):\n",
    "            window = ts[start:start + WINDOW_SIZE, :]\n",
    "            feats = extract_features(window)\n",
    "            subj_feats.append(feats)\n",
    "        # Aggregate across all windows for this subject (mean)\n",
    "        subj_feats = np.mean(subj_feats, axis=0)\n",
    "        all_feats.append(subj_feats)\n",
    "        all_labels.append(label)\n",
    "    return np.array(all_feats), np.array(all_labels)\n",
    "\n",
    "train_X, train_y = process_subjects(train_ids)\n",
    "test_X, test_y = process_subjects(test_ids)\n",
    "\n",
    "# ANOVA\n",
    "f_scores = []\n",
    "p_values = []\n",
    "for i in range(train_X.shape[1]):\n",
    "    group_feats = [train_X[train_y == c, i] for c in np.unique(train_y)]\n",
    "    f, p = f_oneway(*group_feats)\n",
    "    f_scores.append(f)\n",
    "    p_values.append(p)\n",
    "\n",
    "# Report significant features\n",
    "print(\"\\nSignificant Features (p < 0.05):\")\n",
    "significant_features = []\n",
    "significant_indices = []\n",
    "for i, (f, p) in enumerate(zip(f_scores, p_values)):\n",
    "    if p < 0.05:\n",
    "        print(f\"{all_feature_names[i]}: F = {f:.2f}, p = {p:.4f}\")\n",
    "        significant_features.append(all_feature_names[i])\n",
    "        significant_indices.append(i)\n",
    "\n",
    "# Filter train and test data based on significant features\n",
    "train_X_sig = train_X[:, significant_indices]\n",
    "test_X_sig = test_X[:, significant_indices]\n",
    "\n",
    "# Random Forest Classification\n",
    "print(\"\\n--- Random Forest Classifier ---\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(train_X_sig, train_y)\n",
    "preds_rf = rf.predict(test_X_sig)\n",
    "print(\"Accuracy:\", accuracy_score(test_y, preds_rf))\n",
    "print(\"Feature Importances:\")\n",
    "for name, importance in zip(significant_features, rf.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_y, preds_rf))\n",
    "\n",
    "# XGBoost Classification\n",
    "print(\"\\n--- XGBoost Classifier ---\")\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb.fit(train_X_sig, train_y)\n",
    "preds_xgb = xgb.predict(test_X_sig)\n",
    "print(\"Accuracy:\", accuracy_score(test_y, preds_xgb))\n",
    "print(\"Feature Importances:\")\n",
    "for name, importance in zip(significant_features, xgb.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_y, preds_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
