{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from captum.attr import IntegratedGradients, Saliency, LayerConductance\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class NetworkExplainer:\n",
    "    \"\"\"Explainability wrapper for your MultiBandAttentionFusion model\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device='cuda'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: Your trained MultiBandAttentionFusion model\n",
    "            device: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.model.eval()  # Set to evaluation mode\n",
    "        self.device = device\n",
    "        \n",
    "    def prepare_input(self, subject_data):\n",
    "        \"\"\"Convert subject data to format suitable for Captum\"\"\"\n",
    "        processed_subject = []\n",
    "        for band_graphs in subject_data:\n",
    "            band_graphs = [g.to(self.device) for g in band_graphs]\n",
    "            processed_subject.append(band_graphs)\n",
    "        return tuple(processed_subject)\n",
    "    \n",
    "    def explain_with_integrated_gradients(self, subject_data, target_class=None):\n",
    "        \"\"\"\n",
    "        Use Integrated Gradients to explain predictions\n",
    "        \n",
    "        Args:\n",
    "            subject_data: Single subject's data (list of band sequences)\n",
    "            target_class: Which class to explain (0 or 1). If None, uses predicted class\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with attributions for each band\n",
    "        \"\"\"\n",
    "        # Prepare input\n",
    "        processed_input = self.prepare_input(subject_data)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            output = self.model([processed_input])\n",
    "            pred_class = output.argmax(1).item()\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = pred_class\n",
    "            \n",
    "        print(f\"Predicted class: {pred_class}, Explaining class: {target_class}\")\n",
    "        \n",
    "        # Create wrapper function for Captum\n",
    "        def forward_func(x):\n",
    "            # x will be the node features we want to explain\n",
    "            return self.model([processed_input])\n",
    "        \n",
    "        # Collect attributions for each band\n",
    "        band_attributions = {}\n",
    "        \n",
    "        for band_idx, band_graphs in enumerate(subject_data):\n",
    "            band_attrs = []\n",
    "            \n",
    "            for graph_idx, graph in enumerate(band_graphs):\n",
    "                # Create baseline (zero features)\n",
    "                baseline = torch.zeros_like(graph.x)\n",
    "                \n",
    "                # Wrapper to explain this specific graph\n",
    "                def graph_forward(features):\n",
    "                    # Temporarily replace graph features\n",
    "                    orig_features = graph.x.clone()\n",
    "                    graph.x = features\n",
    "                    output = self.model([processed_input])\n",
    "                    graph.x = orig_features  # Restore\n",
    "                    return output\n",
    "                \n",
    "                # Apply Integrated Gradients\n",
    "                ig = IntegratedGradients(graph_forward)\n",
    "                attributions = ig.attribute(\n",
    "                    graph.x, \n",
    "                    baselines=baseline,\n",
    "                    target=target_class,\n",
    "                    n_steps=50\n",
    "                )\n",
    "                \n",
    "                band_attrs.append(attributions.detach().cpu().numpy())\n",
    "            \n",
    "            band_attributions[f'band_{band_idx}'] = band_attrs\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': pred_class,\n",
    "            'explained_class': target_class,\n",
    "            'band_attributions': band_attributions\n",
    "        }\n",
    "    \n",
    "    def explain_with_saliency(self, subject_data, target_class=None):\n",
    "        \"\"\"\n",
    "        Use Saliency (gradient-based) - FASTEST method\n",
    "        \n",
    "        Similar to integrated gradients but uses simple gradients\n",
    "        \"\"\"\n",
    "        processed_input = self.prepare_input(subject_data)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            output = self.model([processed_input])\n",
    "            pred_class = output.argmax(1).item()\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = pred_class\n",
    "            \n",
    "        print(f\"Predicted class: {pred_class}, Explaining class: {target_class}\")\n",
    "        \n",
    "        band_attributions = {}\n",
    "        \n",
    "        for band_idx, band_graphs in enumerate(subject_data):\n",
    "            band_attrs = []\n",
    "            \n",
    "            for graph in band_graphs:\n",
    "                # Enable gradients for this graph\n",
    "                graph.x.requires_grad = True\n",
    "                \n",
    "                # Forward pass\n",
    "                output = self.model([processed_input])\n",
    "                \n",
    "                # Backward pass\n",
    "                self.model.zero_grad()\n",
    "                output[0, target_class].backward(retain_graph=True)\n",
    "                \n",
    "                # Get gradients (saliency)\n",
    "                attributions = graph.x.grad.detach().cpu().numpy()\n",
    "                band_attrs.append(attributions)\n",
    "                \n",
    "                # Cleanup\n",
    "                graph.x.requires_grad = False\n",
    "            \n",
    "            band_attributions[f'band_{band_idx}'] = band_attrs\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': pred_class,\n",
    "            'explained_class': target_class,\n",
    "            'band_attributions': band_attributions\n",
    "        }\n",
    "    \n",
    "    def visualize_attributions(self, attributions, band_names=None, node_names=None):\n",
    "        \"\"\"\n",
    "        Visualize feature attributions across bands and time\n",
    "        \n",
    "        Args:\n",
    "            attributions: Output from explain_* methods\n",
    "            band_names: List of band names (e.g., ['Alpha', 'Beta'])\n",
    "            node_names: List of node/channel names\n",
    "        \"\"\"\n",
    "        band_attrs = attributions['band_attributions']\n",
    "        n_bands = len(band_attrs)\n",
    "        \n",
    "        if band_names is None:\n",
    "            band_names = [f'Band {i}' for i in range(n_bands)]\n",
    "        \n",
    "        fig, axes = plt.subplots(n_bands, 1, figsize=(12, 4*n_bands))\n",
    "        if n_bands == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for band_idx, band_name in enumerate(band_names):\n",
    "            band_key = f'band_{band_idx}'\n",
    "            if band_key in band_attrs:\n",
    "                # Average across time steps\n",
    "                avg_attrs = np.mean([arr for arr in band_attrs[band_key]], axis=0)\n",
    "                \n",
    "                # Sum across features to get node importance\n",
    "                node_importance = np.abs(avg_attrs).sum(axis=1)\n",
    "                \n",
    "                # Plot\n",
    "                axes[band_idx].bar(range(len(node_importance)), node_importance)\n",
    "                axes[band_idx].set_title(f'{band_name} - Node Importance')\n",
    "                axes[band_idx].set_xlabel('Node Index')\n",
    "                axes[band_idx].set_ylabel('Attribution Magnitude')\n",
    "                \n",
    "                if node_names:\n",
    "                    axes[band_idx].set_xticks(range(len(node_names)))\n",
    "                    axes[band_idx].set_xticklabels(node_names, rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def get_temporal_importance(self, attributions):\n",
    "        \"\"\"\n",
    "        Analyze how importance changes over time\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping band names to temporal importance arrays\n",
    "        \"\"\"\n",
    "        band_attrs = attributions['band_attributions']\n",
    "        temporal_importance = {}\n",
    "        \n",
    "        for band_key, attrs_list in band_attrs.items():\n",
    "            # Sum absolute attributions across nodes and features for each timestep\n",
    "            timestep_importance = [np.abs(arr).sum() for arr in attrs_list]\n",
    "            temporal_importance[band_key] = timestep_importance\n",
    "        \n",
    "        return temporal_importance\n",
    "\n",
    "\n",
    "# ============ USAGE EXAMPLE ============\n",
    "\n",
    "def analyze_saved_models(model_path, test_subject, band_names=['Alpha', 'Beta']):\n",
    "    \"\"\"\n",
    "    Analyze a saved model without retraining\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to saved model weights (.pt file)\n",
    "        test_subject: A single subject's data to explain\n",
    "        band_names: Names of frequency bands\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load your saved model\n",
    "    model = MultiBandAttentionFusion(\n",
    "        num_bands=len(band_names),\n",
    "        hidden_channels=64,\n",
    "        num_classes=2,\n",
    "        dropout_rate=0.5,\n",
    "        num_nodes=19,  # Adjust based on your data\n",
    "        in_channels=18  # Adjust based on your data\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load saved weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = NetworkExplainer(model, device)\n",
    "    \n",
    "    # Fast explanation with Saliency (recommended for quick analysis)\n",
    "    print(\"Computing saliency-based attributions...\")\n",
    "    saliency_attrs = explainer.explain_with_saliency(test_subject)\n",
    "    \n",
    "    # More accurate explanation with Integrated Gradients (slower but better)\n",
    "    print(\"\\nComputing integrated gradients attributions...\")\n",
    "    ig_attrs = explainer.explain_with_integrated_gradients(test_subject)\n",
    "    \n",
    "    # Visualize\n",
    "    fig1 = explainer.visualize_attributions(saliency_attrs, band_names)\n",
    "    plt.savefig('saliency_explanation.png')\n",
    "    \n",
    "    fig2 = explainer.visualize_attributions(ig_attrs, band_names)\n",
    "    plt.savefig('integrated_gradients_explanation.png')\n",
    "    \n",
    "    # Temporal analysis\n",
    "    temporal_imp = explainer.get_temporal_importance(ig_attrs)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for band_name, importance in temporal_imp.items():\n",
    "        plt.plot(importance, label=band_name, marker='o')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Temporal Importance of Each Band')\n",
    "    plt.legend()\n",
    "    plt.savefig('temporal_importance.png')\n",
    "    \n",
    "    print(\"\\nâœ… Analysis complete! Check saved images.\")\n",
    "    \n",
    "    return saliency_attrs, ig_attrs\n",
    "\n",
    "\n",
    "# Example: Load and analyze multiple runs\n",
    "def batch_analyze_runs(num_runs=10, dataset=None, band_names=['Alpha', 'Beta']):\n",
    "    \"\"\"Analyze all saved model runs\"\"\"\n",
    "    \n",
    "    all_attributions = []\n",
    "    \n",
    "    for run in range(1, num_runs + 1):\n",
    "        model_path = f\"results/final_model_run{run}.pt\"\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Skipping run {run}: model not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n=== Analyzing Run {run} ===\")\n",
    "        \n",
    "        # Use first test subject (you can modify this)\n",
    "        test_subject = dataset[0]  # Replace with actual test data\n",
    "        \n",
    "        saliency_attrs, ig_attrs = analyze_saved_models(\n",
    "            model_path, test_subject, band_names\n",
    "        )\n",
    "        \n",
    "        all_attributions.append({\n",
    "            'run': run,\n",
    "            'saliency': saliency_attrs,\n",
    "            'integrated_gradients': ig_attrs\n",
    "        })\n",
    "    \n",
    "    return all_attributions\n",
    "\n",
    "\n",
    "# ============ QUICK START ============\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming you have:\n",
    "    # - Saved model at \"results/final_model_run1.pt\"\n",
    "    # - Test dataset loaded\n",
    "    \n",
    "    band_names = ['alpha', 'beta']\n",
    "    \n",
    "    # Single model analysis\n",
    "    test_subject = dataset[0]  # Replace with your test data\n",
    "    saliency_attrs, ig_attrs = analyze_saved_models(\n",
    "        \"results/final_model_run1.pt\",\n",
    "        test_subject,\n",
    "        band_names\n",
    "    )\n",
    "    \n",
    "    # Or batch analyze all runs\n",
    "    # all_results = batch_analyze_runs(num_runs=10, dataset=test_dataset, band_names=band_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
