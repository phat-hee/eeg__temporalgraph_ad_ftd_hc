{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subjects:   2%|▏         | 2/88 [00:37<27:36, 19.26s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:   3%|▎         | 3/88 [00:43<19:16, 13.60s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:   6%|▌         | 5/88 [01:16<21:04, 15.24s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:   7%|▋         | 6/88 [01:29<19:35, 14.34s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:   8%|▊         | 7/88 [01:44<19:55, 14.75s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:   9%|▉         | 8/88 [01:59<19:23, 14.54s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  10%|█         | 9/88 [02:09<17:19, 13.15s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  11%|█▏        | 10/88 [02:30<20:12, 15.55s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  12%|█▎        | 11/88 [02:49<21:26, 16.70s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  14%|█▎        | 12/88 [03:11<23:22, 18.46s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  15%|█▍        | 13/88 [03:48<29:51, 23.88s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  16%|█▌        | 14/88 [04:14<30:12, 24.50s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  17%|█▋        | 15/88 [04:36<28:50, 23.71s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  18%|█▊        | 16/88 [04:57<27:46, 23.14s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  19%|█▉        | 17/88 [05:19<26:59, 22.80s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  20%|██        | 18/88 [05:41<26:02, 22.33s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  23%|██▎       | 20/88 [06:41<29:29, 26.03s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  24%|██▍       | 21/88 [07:06<28:28, 25.50s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  25%|██▌       | 22/88 [07:28<27:07, 24.65s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  26%|██▌       | 23/88 [07:57<28:01, 25.86s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  27%|██▋       | 24/88 [08:14<24:50, 23.29s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  28%|██▊       | 25/88 [08:41<25:29, 24.28s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  30%|██▉       | 26/88 [08:59<23:12, 22.45s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  31%|███       | 27/88 [09:20<22:21, 21.99s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  32%|███▏      | 28/88 [09:41<21:44, 21.74s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  33%|███▎      | 29/88 [09:59<20:19, 20.67s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  34%|███▍      | 30/88 [10:14<18:24, 19.05s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  35%|███▌      | 31/88 [10:55<24:17, 25.57s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  36%|███▋      | 32/88 [11:09<20:28, 21.94s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  38%|███▊      | 33/88 [11:29<19:30, 21.28s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  39%|███▊      | 34/88 [12:05<23:20, 25.94s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  40%|███▉      | 35/88 [12:29<22:23, 25.34s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  42%|████▏     | 37/88 [13:13<19:59, 23.52s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  43%|████▎     | 38/88 [13:37<19:40, 23.60s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  44%|████▍     | 39/88 [14:06<20:35, 25.21s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  45%|████▌     | 40/88 [14:25<18:37, 23.28s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  47%|████▋     | 41/88 [14:55<19:50, 25.33s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  50%|█████     | 44/88 [16:21<20:28, 27.91s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  51%|█████     | 45/88 [16:37<17:19, 24.17s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  52%|█████▏    | 46/88 [17:06<18:06, 25.86s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  53%|█████▎    | 47/88 [17:25<16:10, 23.68s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  55%|█████▍    | 48/88 [17:46<15:15, 22.88s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  56%|█████▌    | 49/88 [18:04<13:53, 21.36s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  57%|█████▋    | 50/88 [18:33<15:04, 23.80s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  58%|█████▊    | 51/88 [18:49<13:10, 21.37s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  59%|█████▉    | 52/88 [19:19<14:20, 23.89s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  60%|██████    | 53/88 [19:35<12:31, 21.46s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  61%|██████▏   | 54/88 [20:05<13:37, 24.04s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  62%|██████▎   | 55/88 [20:22<12:07, 22.04s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  65%|██████▍   | 57/88 [21:03<11:16, 21.82s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  66%|██████▌   | 58/88 [21:20<10:12, 20.42s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  67%|██████▋   | 59/88 [21:50<11:19, 23.42s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  68%|██████▊   | 60/88 [22:08<10:09, 21.75s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  69%|██████▉   | 61/88 [22:38<10:56, 24.33s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  70%|███████   | 62/88 [22:58<09:52, 22.79s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  72%|███████▏  | 63/88 [23:29<10:31, 25.26s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  74%|███████▍  | 65/88 [24:27<10:39, 27.79s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  76%|███████▌  | 67/88 [25:09<08:46, 25.06s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  77%|███████▋  | 68/88 [25:22<07:08, 21.43s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  80%|███████▉  | 70/88 [26:11<07:08, 23.79s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  81%|████████  | 71/88 [26:26<06:00, 21.22s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  82%|████████▏ | 72/88 [26:43<05:17, 19.84s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  83%|████████▎ | 73/88 [27:14<05:48, 23.21s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  84%|████████▍ | 74/88 [27:38<05:26, 23.33s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  86%|████████▋ | 76/88 [28:29<04:51, 24.29s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  88%|████████▊ | 77/88 [28:57<04:39, 25.37s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  89%|████████▊ | 78/88 [29:34<04:48, 28.86s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  90%|████████▉ | 79/88 [29:58<04:05, 27.31s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  91%|█████████ | 80/88 [30:41<04:17, 32.19s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  95%|█████████▌| 84/88 [32:11<01:34, 23.67s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  97%|█████████▋| 85/88 [32:24<01:01, 20.52s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  98%|█████████▊| 86/88 [32:30<00:31, 15.90s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects:  99%|█████████▉| 87/88 [32:45<00:15, 15.66s/it]C:\\Users\\fathi\\AppData\\Local\\Temp\\ipykernel_16712\\2241562197.py:77: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
      "Subjects: 100%|██████████| 88/88 [33:02<00:00, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished saving spectrograms for all segment lengths (paper-style).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import mne\n",
    "from scipy.signal import stft\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ---------------------------\n",
    "# Labeling function\n",
    "# ---------------------------\n",
    "def get_label(s):\n",
    "    if 1 <= s <= 36:\n",
    "        return 2  # AD\n",
    "    elif 37 <= s <= 65:\n",
    "        return 0  # HC\n",
    "    elif 66 <= s <= 88:\n",
    "        return 1  # FTD\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# Brain lobe mapping\n",
    "# ---------------------------\n",
    "BRAIN_LOBES = {\n",
    "    \"frontal\":   [\"Fp1\",\"Fp2\",\"F7\",\"F3\",\"Fz\",\"F4\",\"F8\"],\n",
    "    \"central\":   [\"C3\",\"Cz\",\"C4\"],\n",
    "    \"temporal\":  [\"T3\",\"T4\",\"T5\",\"T6\"],\n",
    "    \"parietal\":  [\"P3\",\"P4\",\"Pz\"],\n",
    "    \"occipital\": [\"O1\",\"O2\",\"Oz\"],\n",
    "    \"full\": None\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# STFT to spectrogram\n",
    "# ---------------------------\n",
    "def compute_spectrogram(signal, fs, size=224):\n",
    "    f, t, Zxx = stft(signal, fs=fs, nperseg=256, noverlap=128, window=\"hamming\")\n",
    "    spec = np.abs(Zxx)\n",
    "    # normalize\n",
    "    spec = (spec - spec.min()) / (spec.max() - spec.min() + 1e-8)\n",
    "    # resize to 224x224\n",
    "    return resize(spec, (size, size), anti_aliasing=True).astype(np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    INPUT_DIR = r\"C:\\Users\\fathi\\Desktop\\Rest_eeg_ds004504-download\\derivatives\"\n",
    "    SAVE_DIR  = r\"C:\\Users\\fathi\\Desktop\\EEG_spectrograms_npy\"\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    FS_ORIG = 500\n",
    "    FS_TARGET = 256   # paper resample\n",
    "\n",
    "    SEGMENTS = {\n",
    "        \"5s\":   5,\n",
    "        \"10s\":  10,\n",
    "        \"15s\":  15,\n",
    "        \"20s\":  20,\n",
    "        \"25s\":  25,\n",
    "        \"30s\":  30,\n",
    "    }\n",
    "\n",
    "    for sub_folder in tqdm(os.listdir(INPUT_DIR), desc=\"Subjects\"):\n",
    "        if not sub_folder.startswith(\"sub-\"):\n",
    "            continue\n",
    "\n",
    "        subj_id = int(sub_folder.split(\"-\")[1])\n",
    "        label_val = get_label(subj_id)\n",
    "        if label_val is None:\n",
    "            continue\n",
    "\n",
    "        eeg_path = os.path.join(INPUT_DIR, sub_folder, \"eeg\", f\"{sub_folder}_task-eyesclosed_eeg.set\")\n",
    "        if not os.path.exists(eeg_path):\n",
    "            continue\n",
    "\n",
    "        raw = mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
    "        raw.resample(FS_TARGET)  # resample to match paper\n",
    "\n",
    "        # Collect boundary annotations\n",
    "        boundaries = [\n",
    "            (int(ann[\"onset\"] * FS_TARGET), int((ann[\"onset\"] + ann[\"duration\"]) * FS_TARGET))\n",
    "            for ann in raw.annotations if ann[\"description\"].lower() == \"boundary\"\n",
    "        ]\n",
    "\n",
    "        data = raw.get_data()\n",
    "        ch_names = raw.ch_names\n",
    "        total_len = data.shape[1]\n",
    "\n",
    "        for seg_name, seg_sec in SEGMENTS.items():\n",
    "            seg_len = seg_sec * FS_TARGET\n",
    "            stride = seg_len  # no overlap\n",
    "            num_segments = (total_len - seg_len) // stride + 1\n",
    "\n",
    "            for i in range(num_segments):\n",
    "                start, end = i * stride, i * stride + seg_len\n",
    "\n",
    "                # skip if segment overlaps boundary\n",
    "                if any((start < b_end and end > b_start) for b_start, b_end in boundaries):\n",
    "                    continue\n",
    "\n",
    "                for lobe_name, channels in BRAIN_LOBES.items():\n",
    "                    if channels is None:\n",
    "                        seg_data = data[:, start:end].mean(axis=0)\n",
    "                    else:\n",
    "                        idx = [ch_names.index(ch) for ch in channels if ch in ch_names]\n",
    "                        if not idx: \n",
    "                            continue\n",
    "                        seg_data = data[idx, start:end].mean(axis=0)\n",
    "\n",
    "                    spec = compute_spectrogram(seg_data, FS_TARGET)\n",
    "\n",
    "                    save_path = os.path.join(SAVE_DIR, seg_name, lobe_name, str(label_val))\n",
    "                    os.makedirs(save_path, exist_ok=True)\n",
    "                    out_file = os.path.join(save_path, f\"{sub_folder}_seg{i}.npy\")\n",
    "                    np.save(out_file, spec)\n",
    "\n",
    "    print(\"✅ Finished saving spectrograms for all segment lengths (paper-style).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, segment=\"5s\", lobe=\"full\", transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: where spectrograms are saved\n",
    "        segment: which window length (e.g. \"5s\", \"10s\")\n",
    "        lobe: which brain lobe (e.g. \"frontal\", \"full\")\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        path = os.path.join(root_dir, segment, lobe)\n",
    "        for label in os.listdir(path):\n",
    "            class_path = os.path.join(path, label)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "            for file in os.listdir(class_path):\n",
    "                if file.endswith(\".npy\"):\n",
    "                    self.samples.append((os.path.join(class_path, file), int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        spec = np.load(file_path)  # (224, 224)\n",
    "        spec = np.expand_dims(spec, axis=0)  # (1, 224, 224) for CNN\n",
    "\n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "\n",
    "        return torch.tensor(spec, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Detected Jupyter, using fallback defaults instead of argparse.\n",
      "\n",
      "================ Experiment: classes0_vs_1 ================\n",
      "\n",
      "----- Segment: 10s | Lobe: central | N=3786 -----\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EEG Spectrogram 5-Fold CV Trainer\n",
    "---------------------------------\n",
    "- Loads ALL segment lengths and ALL brain lobes found under a given root dir.\n",
    "- Runs two binary experiments: (0 vs 1) and (0 vs 2).\n",
    "- Stratified 5-fold CV with class-weighted loss.\n",
    "- Tracks per-epoch validation metrics (accuracy, precision, recall, F1).\n",
    "- Selects the BEST EPOCH per fold by **macro F1** and saves its checkpoint.\n",
    "- Aggregates results across folds, lobes, and segments; finds the best segment length and best lobe by F1.\n",
    "- Saves:\n",
    "    * Per-fold best model checkpoints\n",
    "    * Per-epoch logs per fold (CSV)\n",
    "    * A global summary CSV of all combinations and folds\n",
    "    * A topline CSV highlighting the best segment length and best lobe for each experiment\n",
    "\n",
    "Directory layout expected (created by your generation script):\n",
    "root_dir/\n",
    "  ├── 5s/\n",
    "  │    ├── frontal/0/*.npy, 1/*.npy, 2/*.npy\n",
    "  │    ├── central/...\n",
    "  │    ├── ...\n",
    "  │    └── full/...\n",
    "  ├── 10s/\n",
    "  │    └── ...\n",
    "  └── ...\n",
    "\n",
    "Run:\n",
    "    python eeg_cv_training_pipeline.py \\\n",
    "        --root_dir \"C:/Users/fathi/Desktop/EEG_spectrograms_npy\" \\\n",
    "        --results_dir \"C:/Users/fathi/Desktop/eeg_cv_results\" \\\n",
    "        --epochs 20 --batch_size 32 --lr 1e-3\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "root_dir = r\"C:\\Users\\fathi\\Desktop\\EEG_spectrograms_npy\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, segment: str, lobe: str, classes=(0, 1)):\n",
    "        self.root_dir = root_dir\n",
    "        self.segment = segment\n",
    "        self.lobe = lobe\n",
    "        self.classes = tuple(int(c) for c in classes)  # incoming could be list/tuple\n",
    "\n",
    "        self.samples = []  # (path, mapped_label)\n",
    "        lobe_path = os.path.join(root_dir, segment, lobe)\n",
    "        if not os.path.isdir(lobe_path):\n",
    "            return\n",
    "        # collect .npy files for each of the desired classes\n",
    "        for orig_label in self.classes:\n",
    "            lbl_dir = os.path.join(lobe_path, str(orig_label))\n",
    "            if not os.path.isdir(lbl_dir):\n",
    "                continue\n",
    "            for f in os.listdir(lbl_dir):\n",
    "                if f.endswith('.npy'):\n",
    "                    mapped = self.classes.index(orig_label)  # remap to 0/1\n",
    "                    self.samples.append((os.path.join(lbl_dir, f), mapped))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fpath, y = self.samples[idx]\n",
    "        spec = np.load(fpath)  # (224, 224) float32 normalized\n",
    "        if spec.ndim != 2:\n",
    "            raise ValueError(f\"Expected 2D spectrogram, got shape {spec.shape} for {fpath}\")\n",
    "        x = torch.from_numpy(spec).unsqueeze(0).float()  # (1, H, W)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# Model (matches paper Table 2)\n",
    "# -----------------------------\n",
    "class EEGSpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        # After 4 conv + pooling steps on 224×224 → 14×14\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 256)\n",
    "        self.dropout3 = nn.Dropout(0.50)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "\n",
    "def discover_segments_and_lobes(root_dir: str):\n",
    "    \"\"\"Auto-detect segment folders and lobe folders present on disk.\"\"\"\n",
    "    segments = []\n",
    "    lobes_by_segment = {}\n",
    "    for seg in sorted(os.listdir(root_dir)):\n",
    "        seg_path = os.path.join(root_dir, seg)\n",
    "        if not os.path.isdir(seg_path):\n",
    "            continue\n",
    "        # check that it contains lobe subfolders with label subfolders\n",
    "        lobes = []\n",
    "        for lobe in sorted(os.listdir(seg_path)):\n",
    "            lobe_path = os.path.join(seg_path, lobe)\n",
    "            if not os.path.isdir(lobe_path):\n",
    "                continue\n",
    "            # require at least one class dir\n",
    "            has_class = any(os.path.isdir(os.path.join(lobe_path, str(c))) for c in [0, 1, 2])\n",
    "            if has_class:\n",
    "                lobes.append(lobe)\n",
    "        if lobes:\n",
    "            segments.append(seg)\n",
    "            lobes_by_segment[seg] = lobes\n",
    "    return segments, lobes_by_segment\n",
    "\n",
    "\n",
    "def compute_class_weights(y_train: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"Balanced class weights: n_samples / (n_classes * n_samples_per_class).\"\"\"\n",
    "    values, counts = np.unique(y_train, return_counts=True)\n",
    "    n_samples = len(y_train)\n",
    "    n_classes = len(values)\n",
    "    weights = np.zeros(n_classes, dtype=np.float32)\n",
    "    for v, c in zip(values, counts):\n",
    "        weights[v] = n_samples / (n_classes * float(c))\n",
    "    # if a class is missing (shouldn't happen in train folds), set weight=0\n",
    "    weights[np.isnan(weights)] = 0.0\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = logits.argmax(1).cpu().numpy().tolist()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(yb.numpy().tolist())\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    # macro treats classes equally; weighted accounts for support\n",
    "    prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"precision_macro\": prec_m,\n",
    "        \"recall_macro\": rec_m,\n",
    "        \"f1_macro\": f1_m,\n",
    "        \"precision_weighted\": prec_w,\n",
    "        \"recall_weighted\": rec_w,\n",
    "        \"f1_weighted\": f1_w,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training (single fold with best-epoch selection by F1-macro)\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_fold(\n",
    "    dataset: SpectrogramDataset,\n",
    "    train_idx: np.ndarray,\n",
    "    val_idx: np.ndarray,\n",
    "    device: torch.device,\n",
    "    results_dir: Path,\n",
    "    max_epochs: int = 20,\n",
    "    batch_size: int = 32,\n",
    "    lr: float = 1e-3,\n",
    "    num_workers: int = 2,\n",
    "):\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    y_train = np.array([dataset.samples[i][1] for i in train_idx])\n",
    "    class_weights = compute_class_weights(y_train).to(device)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    model = EEGSpectrogramCNN(num_classes=2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    history_rows = []\n",
    "    best_f1 = -1.0\n",
    "    best_epoch = -1\n",
    "    best_ckpt_path = None\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        n_samples = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            n_samples += xb.size(0)\n",
    "\n",
    "        train_loss = running_loss / max(1, n_samples)\n",
    "\n",
    "        # Validate\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "        row = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            **val_metrics,\n",
    "        }\n",
    "        history_rows.append(row)\n",
    "\n",
    "        # Select best by F1-macro\n",
    "        f1 = val_metrics[\"f1_macro\"]\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epoch = epoch\n",
    "            # Save checkpoint\n",
    "            results_dir.mkdir(parents=True, exist_ok=True)\n",
    "            ckpt_path = results_dir / f\"best_epoch{epoch}.pt\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"state_dict\": model.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"metrics\": val_metrics,\n",
    "                    \"model_kwargs\": {\"num_classes\": 2},\n",
    "                },\n",
    "                ckpt_path,\n",
    "            )\n",
    "            best_ckpt_path = ckpt_path\n",
    "\n",
    "    # Save per-epoch history CSV\n",
    "    hist_df = pd.DataFrame(history_rows)\n",
    "    hist_csv = results_dir / \"history.csv\"\n",
    "    hist_df.to_csv(hist_csv, index=False)\n",
    "\n",
    "    # Reload best and re-evaluate for consistency\n",
    "    if best_ckpt_path is not None:\n",
    "        state = torch.load(best_ckpt_path, map_location=device)\n",
    "        model.load_state_dict(state[\"state_dict\"])\n",
    "    best_metrics = evaluate(model, val_loader, device)\n",
    "\n",
    "    return {\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"best_ckpt\": str(best_ckpt_path) if best_ckpt_path else None,\n",
    "        **best_metrics,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Orchestrator for all segments & lobes\n",
    "# -----------------------------\n",
    "\n",
    "def run_all(\n",
    "    root_dir: str,\n",
    "    results_dir: str,\n",
    "    epochs: int = 20,\n",
    "    batch_size: int = 32,\n",
    "    lr: float = 1e-3,\n",
    "    folds: int = 5,\n",
    "    seed: int = 42,\n",
    "    num_workers: int = 2,\n",
    "):\n",
    "    set_seed(seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    root_dir = os.path.abspath(root_dir)\n",
    "    results_dir = Path(results_dir)\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Discover segments and lobes\n",
    "    segments, lobes_by_segment = discover_segments_and_lobes(root_dir)\n",
    "    if not segments:\n",
    "        raise RuntimeError(f\"No valid segments found under {root_dir}\")\n",
    "\n",
    "    experiments = [(0, 1), (0, 2)]\n",
    "\n",
    "    # Summary rows will hold one row per fold per combo + an extra row for fold='mean'\n",
    "    summary_rows = []\n",
    "\n",
    "    for classes in experiments:\n",
    "        exp_name = f\"classes{classes[0]}_vs_{classes[1]}\"\n",
    "        print(f\"\\n================ Experiment: {exp_name} ================\")\n",
    "        for seg in segments:\n",
    "            lobes = lobes_by_segment.get(seg, [])\n",
    "            for lobe in lobes:\n",
    "                # Build dataset just to inspect size and labels\n",
    "                dataset = SpectrogramDataset(root_dir, seg, lobe, classes=classes)\n",
    "                n_total = len(dataset)\n",
    "                if n_total == 0:\n",
    "                    print(f\"[SKIP] No data for seg={seg}, lobe={lobe}, classes={classes}\")\n",
    "                    continue\n",
    "\n",
    "                y_all = np.array([dataset.samples[i][1] for i in range(len(dataset))])\n",
    "                # Check minimal class count for each class for stratified KFold\n",
    "                class_counts = np.bincount(y_all, minlength=2)\n",
    "                min_class = class_counts.min()\n",
    "                if min_class < folds:\n",
    "                    print(\n",
    "                        f\"[SKIP] Not enough samples per class (min={min_class}) for Stratified {folds}-fold: \"\n",
    "                        f\"seg={seg}, lobe={lobe}, classes={classes}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                print(f\"\\n----- Segment: {seg} | Lobe: {lobe} | N={n_total} -----\")\n",
    "\n",
    "                X_idx = np.arange(n_total)\n",
    "                skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "                for fold_i, (train_idx, val_idx) in enumerate(skf.split(X_idx, y_all), start=1):\n",
    "                    fold_dir = results_dir / exp_name / seg / lobe / f\"fold{fold_i}\"\n",
    "                    metrics = train_one_fold(\n",
    "                        dataset=dataset,\n",
    "                        train_idx=train_idx,\n",
    "                        val_idx=val_idx,\n",
    "                        device=device,\n",
    "                        results_dir=fold_dir,\n",
    "                        max_epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        lr=lr,\n",
    "                        num_workers=num_workers,\n",
    "                    )\n",
    "\n",
    "                    summary_rows.append(\n",
    "                        {\n",
    "                            \"experiment\": exp_name,\n",
    "                            \"segment\": seg,\n",
    "                            \"lobe\": lobe,\n",
    "                            \"fold\": fold_i,\n",
    "                            \"best_epoch\": metrics[\"best_epoch\"],\n",
    "                            \"acc\": metrics[\"acc\"],\n",
    "                            \"precision\": metrics[\"precision_macro\"],\n",
    "                            \"recall\": metrics[\"recall_macro\"],\n",
    "                            \"f1\": metrics[\"f1_macro\"],\n",
    "                            \"acc_w\": metrics[\"acc\"],  # same as acc\n",
    "                            \"precision_w\": metrics[\"precision_weighted\"],\n",
    "                            \"recall_w\": metrics[\"recall_weighted\"],\n",
    "                            \"f1_w\": metrics[\"f1_weighted\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                # After all folds for this (seg,lobe), add mean row\n",
    "                seg_lobe_df = pd.DataFrame([r for r in summary_rows if r[\"experiment\"]==exp_name and r[\"segment\"]==seg and r[\"lobe\"]==lobe and isinstance(r[\"fold\"], int)])\n",
    "                if len(seg_lobe_df) > 0:\n",
    "                    mean_row = {\n",
    "                        \"experiment\": exp_name,\n",
    "                        \"segment\": seg,\n",
    "                        \"lobe\": lobe,\n",
    "                        \"fold\": \"mean\",\n",
    "                        \"best_epoch\": int(np.round(seg_lobe_df[\"best_epoch\"].mean())),\n",
    "                        \"acc\": seg_lobe_df[\"acc\"].mean(),\n",
    "                        \"precision\": seg_lobe_df[\"precision\"].mean(),\n",
    "                        \"recall\": seg_lobe_df[\"recall\"].mean(),\n",
    "                        \"f1\": seg_lobe_df[\"f1\"].mean(),\n",
    "                        \"acc_w\": seg_lobe_df[\"acc_w\"].mean(),\n",
    "                        \"precision_w\": seg_lobe_df[\"precision_w\"].mean(),\n",
    "                        \"recall_w\": seg_lobe_df[\"recall_w\"].mean(),\n",
    "                        \"f1_w\": seg_lobe_df[\"f1_w\"].mean(),\n",
    "                    }\n",
    "                    summary_rows.append(mean_row)\n",
    "\n",
    "    # Save global summary\n",
    "    all_df = pd.DataFrame(summary_rows)\n",
    "    global_csv = results_dir / \"summary_all.csv\"\n",
    "    all_df.to_csv(global_csv, index=False)\n",
    "\n",
    "    # Compute best segment length and best lobe per experiment (by mean F1 across folds)\n",
    "    topline_rows = []\n",
    "    for exp_name in sorted(all_df[\"experiment\"].unique()):\n",
    "        df_exp = all_df[(all_df[\"experiment\"] == exp_name) & (all_df[\"fold\"] == \"mean\")]\n",
    "        if len(df_exp) == 0:\n",
    "            continue\n",
    "        # Best (segment, lobe) combo\n",
    "        best_combo = df_exp.sort_values(\"f1\", ascending=False).iloc[0]\n",
    "\n",
    "        # Best segment length averaged across lobes\n",
    "        seg_rank = (\n",
    "            df_exp.groupby(\"segment\")[\"f1\"].mean().sort_values(ascending=False)\n",
    "        )\n",
    "        best_segment = seg_rank.index[0]\n",
    "        best_segment_f1 = float(seg_rank.iloc[0])\n",
    "\n",
    "        # Best lobe averaged across segments\n",
    "        lobe_rank = (\n",
    "            df_exp.groupby(\"lobe\")[\"f1\"].mean().sort_values(ascending=False)\n",
    "        )\n",
    "        best_lobe = lobe_rank.index[0]\n",
    "        best_lobe_f1 = float(lobe_rank.iloc[0])\n",
    "\n",
    "        topline_rows.append(\n",
    "            {\n",
    "                \"experiment\": exp_name,\n",
    "                \"best_segment_overall\": best_segment,\n",
    "                \"best_segment_f1\": best_segment_f1,\n",
    "                \"best_lobe_overall\": best_lobe,\n",
    "                \"best_lobe_f1\": best_lobe_f1,\n",
    "                \"best_combo_segment\": best_combo[\"segment\"],\n",
    "                \"best_combo_lobe\": best_combo[\"lobe\"],\n",
    "                \"best_combo_f1\": float(best_combo[\"f1\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    topline_df = pd.DataFrame(topline_rows)\n",
    "    topline_csv = results_dir / \"topline_summary.csv\"\n",
    "    topline_df.to_csv(topline_csv, index=False)\n",
    "\n",
    "    print(\"\\n========================================\")\n",
    "    print(\"Training complete. Key summaries saved:\")\n",
    "    print(f\" - Global summary: {global_csv}\")\n",
    "    print(f\" - Topline summary: {topline_csv}\")\n",
    "    if len(topline_df) > 0:\n",
    "        print(\"\\nTopline (per experiment):\")\n",
    "        print(topline_df.to_string(index=False))\n",
    "    print(\"========================================\\n\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CLI\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse, sys\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--root_dir\", type=str, required=True, help=\"Root folder of spectrogram .npy files\")\n",
    "    parser.add_argument(\"--results_dir\", type=str, required=True, help=\"Output folder for checkpoints and CSVs\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=20)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--folds\", type=int, default=5)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=2)\n",
    "\n",
    "    # Detect if running inside Jupyter (ipykernel)\n",
    "    if any(\"ipykernel_launcher\" in arg for arg in sys.argv):\n",
    "        print(\"⚠️ Detected Jupyter, using fallback defaults instead of argparse.\")\n",
    "        class Args: pass\n",
    "        args = Args()\n",
    "        args.root_dir = r\"C:\\Users\\fathi\\Desktop\\EEG_spectrograms_npy\"\n",
    "        args.results_dir = r\"C:\\Users\\fathi\\Desktop\\eeg_cv_results\"\n",
    "        args.epochs = 50\n",
    "        args.batch_size = 32\n",
    "        args.lr = 1e-4\n",
    "        args.folds = 5\n",
    "        args.seed = 42\n",
    "        args.num_workers = 0  # safer for Windows Jupyter\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    run_all(\n",
    "        root_dir=args.root_dir,\n",
    "        results_dir=args.results_dir,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        lr=args.lr,\n",
    "        folds=args.folds,\n",
    "        seed=args.seed,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
